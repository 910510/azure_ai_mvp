from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential

import streamlit as st

import os
from dotenv import load_dotenv

load_dotenv()

search_client = SearchClient(
    endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
    index_name=os.environ["AZURE_SEARCH_INDEX_NAME"],
    credential=AzureKeyCredential(os.environ["AZURE_SEARCH_ADMIN_KEY"])
)

openai_client = AzureOpenAI(
    api_key=os.environ["AZURE_OPENAI_API_KEY"],
    api_version=os.environ["AZURE_OPENAI_VERSION"],
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"]
)

deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")

def run_rag_with_fallback(user_query: str) -> str:
    results = search_client.search(user_query, top=5)
    documents = [doc["content"] for doc in results if "content" in doc]

    if not documents:
        # Fallback: ë¬¸ì„œ ì—†ì´ ì‚¬ìš©ì ì§ˆë¬¸ë§Œ
        prompt = f"""
        ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.
        ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"
        ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
        """
    else:
        # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ contextë¡œ ì‚¬ìš©
        context = "\n\n".join(documents)
        prompt = f"""
        ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

        ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì…ë‹ˆë‹¤:
        -------------------------
        {context}
        -------------------------

        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
        "{user_query}"

        ë¬¸ì„œ ë‚´ìš©ì„ ìµœëŒ€í•œ ë°˜ì˜í•˜ì—¬ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
        """

    # GPT ì‘ë‹µ ìƒì„±
    response = openai_client.chat.completions.create(
        model=deployment,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )

    return response.choices[0].message.content

st.title("Hello")

# if __name__ == "__main__":
#     query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
#     answer = run_rag_with_fallback(query)
#     print("\nğŸ“˜ GPT ì‘ë‹µ:")
#     print(answer)
